{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # statistical data visualization\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = './data/paper-substitution.csv'\n",
    "\n",
    "df = pd.read_csv(data)\n",
    "col_names = ['front_sheet-P', 'c_wave-P', 'middle_sheet-P', 'b_wave-P', 'back_sheet-P', 'front_sheet-O', 'c_wave-O', 'middle_sheet-O', 'b_wave-O', 'back_sheet-O']\n",
    "\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "paper_part = 'front_sheet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Yagdrasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>front_sheet-P</th>\n",
       "      <th>c_wave-P</th>\n",
       "      <th>middle_sheet-P</th>\n",
       "      <th>b_wave-P</th>\n",
       "      <th>back_sheet-P</th>\n",
       "      <th>front_sheet-O</th>\n",
       "      <th>c_wave-O</th>\n",
       "      <th>middle_sheet-O</th>\n",
       "      <th>b_wave-O</th>\n",
       "      <th>back_sheet-O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KAC125</td>\n",
       "      <td>CM112</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KB120</td>\n",
       "      <td>CM97</td>\n",
       "      <td>CM127</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CM97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KS161</td>\n",
       "      <td>CM147</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KB160</td>\n",
       "      <td>KS231</td>\n",
       "      <td>CM127</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KB160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KB230</td>\n",
       "      <td>CM147</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KB160</td>\n",
       "      <td>KB230</td>\n",
       "      <td>CM147</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CM147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KS161</td>\n",
       "      <td>CM147</td>\n",
       "      <td>CM147</td>\n",
       "      <td>CM147</td>\n",
       "      <td>KB160</td>\n",
       "      <td>KS231</td>\n",
       "      <td>CM147</td>\n",
       "      <td>CM147</td>\n",
       "      <td>CM147</td>\n",
       "      <td>KB160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KS161</td>\n",
       "      <td>CM147</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KB160</td>\n",
       "      <td>KS231</td>\n",
       "      <td>CM127</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>KB160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>KB120</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CM112</td>\n",
       "      <td>CM127</td>\n",
       "      <td>KB120</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CME100</td>\n",
       "      <td>CME100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>KL250</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>KL250</td>\n",
       "      <td>KB160</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>KB160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>KAC125</td>\n",
       "      <td>CM112</td>\n",
       "      <td>CM112</td>\n",
       "      <td>CM112</td>\n",
       "      <td>CM112</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>KB230</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>KB160</td>\n",
       "      <td>KB160</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM127</td>\n",
       "      <td>KB160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>CM97</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CM127</td>\n",
       "      <td>CM97</td>\n",
       "      <td>CM85</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CM85</td>\n",
       "      <td>CM85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     front_sheet-P c_wave-P middle_sheet-P b_wave-P back_sheet-P  \\\n",
       "0           KAC125    CM112           None     None        KB120   \n",
       "1            KS161    CM147           None     None        KB160   \n",
       "2            KB230    CM147           None     None        KB160   \n",
       "3            KS161    CM147          CM147    CM147        KB160   \n",
       "4            KS161    CM147           None     None        KB160   \n",
       "...            ...      ...            ...      ...          ...   \n",
       "2078         KB120     None           None    CM112        CM127   \n",
       "2079         KL250    CM127          CM127    CM127        KL250   \n",
       "2080        KAC125    CM112          CM112    CM112        CM112   \n",
       "2081         KB230    CM127          CM127    CM127        KB160   \n",
       "2082          CM97     None           None    CM127         CM97   \n",
       "\n",
       "     front_sheet-O c_wave-O middle_sheet-O b_wave-O back_sheet-O  \n",
       "0             CM97    CM127           None     None         CM97  \n",
       "1            KS231    CM127           None     None        KB160  \n",
       "2            KB230    CM147           None     None        CM147  \n",
       "3            KS231    CM147          CM147    CM147        KB160  \n",
       "4            KS231    CM127           None     None        KB160  \n",
       "...            ...      ...            ...      ...          ...  \n",
       "2078         KB120     None           None   CME100       CME100  \n",
       "2079         KB160    CM127          CM127    CM127        KB160  \n",
       "2080         CM127    CM127          CM127    CM127        CM127  \n",
       "2081         KB160    CM127          CM127    CM127        KB160  \n",
       "2082          CM85     None           None     CM85         CM85  \n",
       "\n",
       "[2083 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ydf  # Yggdrasil Decision Forests\n",
    "import pandas as pd  # We use Pandas to load small datasets\n",
    "from icecream import ic\n",
    "\n",
    "\n",
    "output =  ['front_sheet-P', 'c_wave-P', 'middle_sheet-P', 'b_wave-P', 'back_sheet-P']\n",
    "\n",
    "input = ['front_sheet-O', 'c_wave-O', 'middle_sheet-O', 'b_wave-O', 'back_sheet-O']\n",
    "\n",
    "# Create a mask to identify rows where -P and -O columns are the same\n",
    "mask = (df[['front_sheet-P', 'c_wave-P', 'middle_sheet-P', 'b_wave-P', 'back_sheet-P']].values ==\n",
    "        df[['front_sheet-O', 'c_wave-O', 'middle_sheet-O', 'b_wave-O', 'back_sheet-O']].values).all(axis=1)\n",
    "\n",
    "# Drop the rows where the mask is True\n",
    "df_cleaned = df[~mask].reset_index(drop=True)\n",
    "# df_cleaned = df\n",
    "\n",
    "for i in output+input:\n",
    "    df_cleaned[i] = df_cleaned[i].str.strip().replace('', None).fillna('None')\n",
    "\n",
    "\n",
    "df_train, df_test = train_test_split(df_cleaned, test_size=0.1, random_state=42)\n",
    "\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "max_vocab_count = -1 for column front_sheet-P, the dictionary will not be pruned by size.\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"front_sheet-P\" CATEGORICAL has-dict vocab-size:26 zero-ood-items most-frequent:\"KS231\" 492 (26.254%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"front_sheet-P\" was removed from the input feature set.\n",
      "Training random forest on 1874 example(s) and 5 feature(s).\n",
      "Training of tree  1/300 (tree index:2) done accuracy:0.457903 logloss:19.5392\n",
      "Training of tree  11/300 (tree index:11) done accuracy:0.445757 logloss:16.9427\n",
      "Training of tree  21/300 (tree index:23) done accuracy:0.443376 logloss:15.7275\n",
      "Training of tree  31/300 (tree index:31) done accuracy:0.446638 logloss:13.9035\n",
      "Training of tree  41/300 (tree index:40) done accuracy:0.441836 logloss:13.2327\n",
      "Training of tree  51/300 (tree index:53) done accuracy:0.447172 logloss:13.0324\n",
      "Training of tree  62/300 (tree index:62) done accuracy:0.451974 logloss:12.4438\n",
      "Training of tree  72/300 (tree index:71) done accuracy:0.448239 logloss:12.2813\n",
      "Training of tree  82/300 (tree index:81) done accuracy:0.448239 logloss:12.2558\n",
      "Training of tree  92/300 (tree index:91) done accuracy:0.448239 logloss:12.0768\n",
      "Training of tree  102/300 (tree index:105) done accuracy:0.448239 logloss:11.9773\n",
      "Training of tree  112/300 (tree index:112) done accuracy:0.446105 logloss:11.9386\n",
      "Training of tree  122/300 (tree index:121) done accuracy:0.44984 logloss:11.9256\n",
      "Training of tree  132/300 (tree index:132) done accuracy:0.44984 logloss:11.8019\n",
      "Training of tree  142/300 (tree index:142) done accuracy:0.450374 logloss:11.7301\n",
      "Training of tree  152/300 (tree index:151) done accuracy:0.449306 logloss:11.713\n",
      "Training of tree  162/300 (tree index:161) done accuracy:0.44984 logloss:11.6934\n",
      "Training of tree  172/300 (tree index:172) done accuracy:0.446638 logloss:11.6968\n",
      "Training of tree  182/300 (tree index:181) done accuracy:0.447705 logloss:11.6773\n",
      "Training of tree  192/300 (tree index:191) done accuracy:0.450907 logloss:11.6451\n",
      "Training of tree  202/300 (tree index:197) done accuracy:0.44984 logloss:11.5975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.287704\n",
      "front_sheet-Ptest accuracy: 0.4258373205741627\n",
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training of tree  212/300 (tree index:212) done accuracy:0.448239 logloss:11.5831\n",
      "Training of tree  223/300 (tree index:221) done accuracy:0.44984 logloss:11.57\n",
      "Training of tree  233/300 (tree index:233) done accuracy:0.451441 logloss:11.5535\n",
      "Training of tree  243/300 (tree index:242) done accuracy:0.450374 logloss:11.5358\n",
      "Training of tree  253/300 (tree index:253) done accuracy:0.450374 logloss:11.5159\n",
      "Training of tree  263/300 (tree index:258) done accuracy:0.450374 logloss:11.518\n",
      "Training of tree  273/300 (tree index:274) done accuracy:0.450374 logloss:11.5012\n",
      "Training of tree  283/300 (tree index:283) done accuracy:0.450907 logloss:11.4998\n",
      "Training of tree  293/300 (tree index:292) done accuracy:0.44984 logloss:11.4989\n",
      "Training of tree  300/300 (tree index:299) done accuracy:0.450907 logloss:11.468\n",
      "Final OOB metrics: accuracy:0.450907 logloss:11.468\n",
      "Model loaded with 300 root(s), 23362 node(s), and 5 input feature(s).\n",
      "Engine \"RandomForestGeneric\" built\n",
      "max_vocab_count = -1 for column c_wave-P, the dictionary will not be pruned by size.\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"c_wave-P\" CATEGORICAL has-dict vocab-size:8 zero-ood-items most-frequent:\"CM127\" 1109 (59.1782%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"c_wave-P\" was removed from the input feature set.\n",
      "Training random forest on 1874 example(s) and 5 feature(s).\n",
      "Training of tree  1/300 (tree index:1) done accuracy:0.6875 logloss:11.2636\n",
      "Training of tree  11/300 (tree index:3) done accuracy:0.702586 logloss:10.1126\n",
      "Training of tree  21/300 (tree index:20) done accuracy:0.706197 logloss:9.90501\n",
      "Training of tree  32/300 (tree index:33) done accuracy:0.704376 logloss:9.76941\n",
      "Training of tree  43/300 (tree index:43) done accuracy:0.702775 logloss:9.6466\n",
      "Training of tree  54/300 (tree index:53) done accuracy:0.702775 logloss:9.63027\n",
      "Training of tree  64/300 (tree index:63) done accuracy:0.701708 logloss:9.43939\n",
      "Training of tree  74/300 (tree index:73) done accuracy:0.702775 logloss:9.44158\n",
      "Training of tree  86/300 (tree index:85) done accuracy:0.702775 logloss:9.39049\n",
      "Training of tree  97/300 (tree index:95) done accuracy:0.703308 logloss:9.37343\n",
      "Training of tree  107/300 (tree index:107) done accuracy:0.702775 logloss:9.32335\n",
      "Training of tree  117/300 (tree index:116) done accuracy:0.702241 logloss:9.32438\n",
      "Training of tree  127/300 (tree index:126) done accuracy:0.701708 logloss:9.23809\n",
      "Training of tree  137/300 (tree index:136) done accuracy:0.702241 logloss:9.22258\n",
      "Training of tree  147/300 (tree index:146) done accuracy:0.702241 logloss:9.20701\n",
      "Training of tree  157/300 (tree index:156) done accuracy:0.702241 logloss:9.17377\n",
      "Training of tree  167/300 (tree index:166) done accuracy:0.702775 logloss:9.17498\n",
      "Training of tree  177/300 (tree index:176) done accuracy:0.702775 logloss:9.14121\n",
      "Training of tree  187/300 (tree index:187) done accuracy:0.702241 logloss:9.14246\n",
      "Training of tree  197/300 (tree index:197) done accuracy:0.702241 logloss:9.14352\n",
      "Training of tree  207/300 (tree index:207) done accuracy:0.701708 logloss:9.14264\n",
      "Training of tree  218/300 (tree index:217) done accuracy:0.702775 logloss:9.14297\n",
      "Training of tree  228/300 (tree index:227) done accuracy:0.702775 logloss:9.14394\n",
      "Training of tree  238/300 (tree index:237) done accuracy:0.702241 logloss:9.14435\n",
      "Training of tree  249/300 (tree index:248) done accuracy:0.702241 logloss:9.14547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.092556\n",
      "c_wave-Ptest accuracy: 0.6650717703349283\n",
      "Train model on 1874 examples\n",
      "Model trained in 0:00:00.065472\n",
      "middle_sheet-Ptest accuracy: 0.8133971291866029\n",
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training of tree  259/300 (tree index:258) done accuracy:0.701174 logloss:9.14663\n",
      "Training of tree  269/300 (tree index:269) done accuracy:0.701174 logloss:9.11336\n",
      "Training of tree  279/300 (tree index:279) done accuracy:0.701174 logloss:9.11429\n",
      "Training of tree  290/300 (tree index:289) done accuracy:0.701708 logloss:9.09783\n",
      "Training of tree  300/300 (tree index:299) done accuracy:0.701174 logloss:9.09857\n",
      "Final OOB metrics: accuracy:0.701174 logloss:9.09857\n",
      "Model loaded with 300 root(s), 17138 node(s), and 5 input feature(s).\n",
      "max_vocab_count = -1 for column middle_sheet-P, the dictionary will not be pruned by size.\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"middle_sheet-P\" CATEGORICAL has-dict vocab-size:9 zero-ood-items most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"middle_sheet-P\" was removed from the input feature set.\n",
      "Training random forest on 1874 example(s) and 5 feature(s).\n",
      "Training of tree  1/300 (tree index:2) done accuracy:0.868538 logloss:4.73838\n",
      "Training of tree  11/300 (tree index:10) done accuracy:0.86627 logloss:4.74655\n",
      "Training of tree  21/300 (tree index:20) done accuracy:0.866987 logloss:4.68802\n",
      "Training of tree  31/300 (tree index:29) done accuracy:0.866596 logloss:4.64695\n",
      "Training of tree  43/300 (tree index:43) done accuracy:0.866062 logloss:4.64722\n",
      "Training of tree  53/300 (tree index:52) done accuracy:0.866062 logloss:4.62962\n",
      "Training of tree  63/300 (tree index:64) done accuracy:0.865528 logloss:4.62922\n",
      "Training of tree  73/300 (tree index:73) done accuracy:0.865528 logloss:4.62979\n",
      "Training of tree  83/300 (tree index:82) done accuracy:0.864995 logloss:4.59484\n",
      "Training of tree  93/300 (tree index:92) done accuracy:0.865528 logloss:4.59476\n",
      "Training of tree  103/300 (tree index:100) done accuracy:0.866062 logloss:4.59495\n",
      "Training of tree  114/300 (tree index:113) done accuracy:0.865528 logloss:4.59495\n",
      "Training of tree  124/300 (tree index:125) done accuracy:0.865528 logloss:4.59467\n",
      "Training of tree  134/300 (tree index:132) done accuracy:0.865528 logloss:4.59476\n",
      "Training of tree  146/300 (tree index:146) done accuracy:0.865528 logloss:4.59463\n",
      "Training of tree  156/300 (tree index:155) done accuracy:0.865528 logloss:4.5948\n",
      "Training of tree  167/300 (tree index:167) done accuracy:0.865528 logloss:4.59522\n",
      "Training of tree  178/300 (tree index:177) done accuracy:0.865528 logloss:4.59492\n",
      "Training of tree  188/300 (tree index:183) done accuracy:0.865528 logloss:4.59477\n",
      "Training of tree  198/300 (tree index:197) done accuracy:0.865528 logloss:4.59475\n",
      "Training of tree  208/300 (tree index:207) done accuracy:0.865528 logloss:4.59472\n",
      "Training of tree  218/300 (tree index:216) done accuracy:0.865528 logloss:4.59475\n",
      "Training of tree  228/300 (tree index:227) done accuracy:0.865528 logloss:4.59493\n",
      "Training of tree  238/300 (tree index:238) done accuracy:0.865528 logloss:4.59497\n",
      "Training of tree  249/300 (tree index:248) done accuracy:0.865528 logloss:4.59495\n",
      "Training of tree  260/300 (tree index:259) done accuracy:0.865528 logloss:4.59481\n",
      "Training of tree  270/300 (tree index:270) done accuracy:0.866062 logloss:4.59483\n",
      "Training of tree  280/300 (tree index:279) done accuracy:0.865528 logloss:4.59489\n",
      "Training of tree  290/300 (tree index:289) done accuracy:0.865528 logloss:4.5949\n",
      "Training of tree  300/300 (tree index:299) done accuracy:0.865528 logloss:4.57833\n",
      "Final OOB metrics: accuracy:0.865528 logloss:4.57833\n",
      "Model loaded with 300 root(s), 7254 node(s), and 5 input feature(s).\n",
      "max_vocab_count = -1 for column b_wave-P, the dictionary will not be pruned by size.\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"b_wave-P\" CATEGORICAL has-dict vocab-size:9 zero-ood-items most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"b_wave-P\" was removed from the input feature set.\n",
      "Training random forest on 1874 example(s) and 5 feature(s).\n",
      "Training of tree  1/300 (tree index:2) done accuracy:0.874446 logloss:4.52542\n",
      "Training of tree  11/300 (tree index:11) done accuracy:0.869471 logloss:4.11157\n",
      "Training of tree  22/300 (tree index:21) done accuracy:0.872465 logloss:4.05128\n",
      "Training of tree  35/300 (tree index:33) done accuracy:0.875133 logloss:4.01649\n",
      "Training of tree  45/300 (tree index:44) done accuracy:0.875133 logloss:3.97943\n",
      "Training of tree  55/300 (tree index:54) done accuracy:0.875667 logloss:3.97786\n",
      "Training of tree  65/300 (tree index:63) done accuracy:0.876201 logloss:3.96035\n",
      "Training of tree  75/300 (tree index:74) done accuracy:0.875133 logloss:3.95994\n",
      "Training of tree  85/300 (tree index:84) done accuracy:0.8746 logloss:3.94175\n",
      "Training of tree  95/300 (tree index:93) done accuracy:0.8746 logloss:3.94186\n",
      "Training of tree  105/300 (tree index:104) done accuracy:0.8746 logloss:3.94165\n",
      "Training of tree  116/300 (tree index:115) done accuracy:0.8746 logloss:3.941\n",
      "Training of tree  127/300 (tree index:126) done accuracy:0.8746 logloss:3.92361\n",
      "Training of tree  137/300 (tree index:136) done accuracy:0.8746 logloss:3.92347\n",
      "Training of tree  147/300 (tree index:146) done accuracy:0.874066 logloss:3.92347\n",
      "Training of tree  158/300 (tree index:157) done accuracy:0.874066 logloss:3.90639\n",
      "Training of tree  168/300 (tree index:167) done accuracy:0.874066 logloss:3.9063\n",
      "Training of tree  178/300 (tree index:177) done accuracy:0.874066 logloss:3.90631\n",
      "Training of tree  189/300 (tree index:188) done accuracy:0.874066 logloss:3.88937\n",
      "Training of tree  201/300 (tree index:200) done accuracy:0.874066 logloss:3.88947\n",
      "Training of tree  212/300 (tree index:211) done accuracy:0.8746 logloss:3.88975\n",
      "Training of tree  222/300 (tree index:221) done accuracy:0.874066 logloss:3.88992\n",
      "Training of tree  232/300 (tree index:231) done accuracy:0.874066 logloss:3.87305\n",
      "Training of tree  242/300 (tree index:241) done accuracy:0.874066 logloss:3.8731\n",
      "Training of tree  252/300 (tree index:251) done accuracy:0.874066 logloss:3.85624\n",
      "Training of tree  263/300 (tree index:262) done accuracy:0.874066 logloss:3.85653\n",
      "Training of tree  273/300 (tree index:272) done accuracy:0.874066 logloss:3.85676\n",
      "Training of tree  283/300 (tree index:282) done accuracy:0.874066 logloss:3.85672\n",
      "Training of tree  294/300 (tree index:294) done accuracy:0.874066 logloss:3.85697\n",
      "Training of tree  300/300 (tree index:299) done accuracy:0.874066 logloss:3.84037\n",
      "Final OOB metrics: accuracy:0.874066 logloss:3.84037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.071402\n",
      "b_wave-Ptest accuracy: 0.84688995215311\n",
      "Train model on 1874 examples\n",
      "Model trained in 0:00:00.177374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model loaded with 300 root(s), 11440 node(s), and 5 input feature(s).\n",
      "max_vocab_count = -1 for column back_sheet-P, the dictionary will not be pruned by size.\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"back_sheet-P\" CATEGORICAL has-dict vocab-size:18 zero-ood-items most-frequent:\"KB160\" 624 (33.2978%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"back_sheet-P\" was removed from the input feature set.\n",
      "Training random forest on 1874 example(s) and 5 feature(s).\n",
      "Training of tree  1/300 (tree index:5) done accuracy:0.545058 logloss:16.3978\n",
      "Training of tree  11/300 (tree index:12) done accuracy:0.55478 logloss:14.5178\n",
      "Training of tree  21/300 (tree index:20) done accuracy:0.557158 logloss:12.9034\n",
      "Training of tree  31/300 (tree index:30) done accuracy:0.557631 logloss:12.7189\n",
      "Training of tree  41/300 (tree index:40) done accuracy:0.560299 logloss:12.2936\n",
      "Training of tree  51/300 (tree index:53) done accuracy:0.559765 logloss:12.1902\n",
      "Training of tree  61/300 (tree index:60) done accuracy:0.558698 logloss:12.0491\n",
      "Training of tree  71/300 (tree index:70) done accuracy:0.559765 logloss:12.0047\n",
      "Training of tree  81/300 (tree index:82) done accuracy:0.558164 logloss:11.7314\n",
      "Training of tree  91/300 (tree index:89) done accuracy:0.560299 logloss:11.7025\n",
      "Training of tree  101/300 (tree index:101) done accuracy:0.558164 logloss:11.6315\n",
      "Training of tree  112/300 (tree index:111) done accuracy:0.559232 logloss:11.5549\n",
      "Training of tree  122/300 (tree index:123) done accuracy:0.560832 logloss:11.4486\n",
      "Training of tree  132/300 (tree index:131) done accuracy:0.560832 logloss:11.3974\n",
      "Training of tree  142/300 (tree index:134) done accuracy:0.561366 logloss:11.4014\n",
      "Training of tree  152/300 (tree index:152) done accuracy:0.560299 logloss:11.4026\n",
      "Training of tree  162/300 (tree index:162) done accuracy:0.559765 logloss:11.4\n",
      "Training of tree  172/300 (tree index:172) done accuracy:0.559765 logloss:11.3664\n",
      "Training of tree  182/300 (tree index:181) done accuracy:0.559765 logloss:11.3683\n",
      "Training of tree  192/300 (tree index:191) done accuracy:0.559232 logloss:11.3659\n",
      "Training of tree  202/300 (tree index:201) done accuracy:0.558698 logloss:11.3517\n",
      "Training of tree  212/300 (tree index:210) done accuracy:0.558698 logloss:11.3208\n",
      "Training of tree  222/300 (tree index:221) done accuracy:0.557631 logloss:11.3068\n",
      "Training of tree  232/300 (tree index:232) done accuracy:0.557631 logloss:11.2899\n",
      "Training of tree  242/300 (tree index:242) done accuracy:0.557631 logloss:11.2918\n",
      "Training of tree  252/300 (tree index:252) done accuracy:0.557097 logloss:11.2877\n",
      "Training of tree  262/300 (tree index:259) done accuracy:0.556563 logloss:11.2814\n",
      "Training of tree  272/300 (tree index:271) done accuracy:0.556563 logloss:11.2837\n",
      "Training of tree  282/300 (tree index:281) done accuracy:0.557631 logloss:11.1686\n",
      "Training of tree  292/300 (tree index:291) done accuracy:0.557631 logloss:11.1664\n",
      "Training of tree  300/300 (tree index:298) done accuracy:0.557631 logloss:11.166\n",
      "Final OOB metrics: accuracy:0.557631 logloss:11.166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back_sheet-Ptest accuracy: 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model loaded with 300 root(s), 23994 node(s), and 5 input feature(s).\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "\n",
    "for paper in output:\n",
    "    model[paper] = ydf.RandomForestLearner(label=f'{paper}', features=input, task=ydf.Task.CLASSIFICATION).train(df_train)\n",
    "    # model[paper].save(f\"modules/yggdrasil_models/{paper}\")\n",
    "    evaluation = model[paper].evaluate(df_test)\n",
    "    # Query individual evaluation metrics\n",
    "    print(f\"{paper}test accuracy: {evaluation.accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_vocab_count = -1 for column front_sheet-P, the dictionary will not be pruned by size.\n",
      "\"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"front_sheet-P\" CATEGORICAL has-dict vocab-size:26 zero-ood-items most-frequent:\"KS231\" 492 (26.254%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"front_sheet-P\" was removed from the input feature set.\n",
      "Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "Training gradient boosted tree on 1874 example(s) and 5 feature(s).\n",
      "1709 examples used for training and 165 examples used for validation\n",
      "\tnum-trees:1 train-loss:2.441184 train-accuracy:0.480398 valid-loss:2.469079 valid-accuracy:0.466667\n",
      "\tnum-trees:2 train-loss:2.214818 train-accuracy:0.480983 valid-loss:2.253208 valid-accuracy:0.466667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:01.177108\n",
      "front_sheet-Ptest accuracy: 0.4258373205741627\n",
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.58684\n",
      "Truncates the model to 675 tree(s) i.e. 27  iteration(s).\n",
      "Final model num-trees:27 valid-loss:1.586838 valid-accuracy:0.466667\n",
      "Model loaded with 675 root(s), 24229 node(s), and 5 input feature(s).\n",
      "max_vocab_count = -1 for column c_wave-P, the dictionary will not be pruned by size.\n",
      "\"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"c_wave-P\" CATEGORICAL has-dict vocab-size:8 zero-ood-items most-frequent:\"CM127\" 1109 (59.1782%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"c_wave-P\" was removed from the input feature set.\n",
      "Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "Training gradient boosted tree on 1874 example(s) and 5 feature(s).\n",
      "1709 examples used for training and 165 examples used for validation\n",
      "\tnum-trees:1 train-loss:1.611437 train-accuracy:0.705676 valid-loss:1.615493 valid-accuracy:0.709091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:01.149503\n",
      "c_wave-Ptest accuracy: 0.6650717703349283\n",
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.740479\n",
      "Truncates the model to 630 tree(s) i.e. 90  iteration(s).\n",
      "Final model num-trees:90 valid-loss:0.740479 valid-accuracy:0.721212\n",
      "Model loaded with 630 root(s), 22010 node(s), and 5 input feature(s).\n",
      "max_vocab_count = -1 for column middle_sheet-P, the dictionary will not be pruned by size.\n",
      "\"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"middle_sheet-P\" CATEGORICAL has-dict vocab-size:9 zero-ood-items most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"middle_sheet-P\" was removed from the input feature set.\n",
      "Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "Training gradient boosted tree on 1874 example(s) and 5 feature(s).\n",
      "1709 examples used for training and 165 examples used for validation\n",
      "\tnum-trees:1 train-loss:1.494749 train-accuracy:0.871270 valid-loss:1.534318 valid-accuracy:0.830303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:00.519439\n",
      "middle_sheet-Ptest accuracy: 0.8133971291866029\n",
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.460347\n",
      "Truncates the model to 280 tree(s) i.e. 35  iteration(s).\n",
      "Final model num-trees:35 valid-loss:0.460347 valid-accuracy:0.830303\n",
      "Model loaded with 280 root(s), 8592 node(s), and 5 input feature(s).\n",
      "max_vocab_count = -1 for column b_wave-P, the dictionary will not be pruned by size.\n",
      "\"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"b_wave-P\" CATEGORICAL has-dict vocab-size:9 zero-ood-items most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"b_wave-P\" was removed from the input feature set.\n",
      "Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "Training gradient boosted tree on 1874 example(s) and 5 feature(s).\n",
      "1709 examples used for training and 165 examples used for validation\n",
      "\tnum-trees:1 train-loss:1.492181 train-accuracy:0.877706 valid-loss:1.511489 valid-accuracy:0.866667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:01.393786\n",
      "b_wave-Ptest accuracy: 0.84688995215311\n",
      "Train model on 1874 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 0.337948\n",
      "Truncates the model to 792 tree(s) i.e. 99  iteration(s).\n",
      "Final model num-trees:99 valid-loss:0.337948 valid-accuracy:0.878788\n",
      "Model loaded with 792 root(s), 26084 node(s), and 5 input feature(s).\n",
      "max_vocab_count = -1 for column back_sheet-P, the dictionary will not be pruned by size.\n",
      "\"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
      "\"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
      "Data spec:\n",
      "Number of records: 1874\n",
      "Number of columns: 6\n",
      "\n",
      "Number of columns by type:\n",
      "\tCATEGORICAL: 6 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "CATEGORICAL: 6 (100%)\n",
      "\t0: \"front_sheet-O\" CATEGORICAL has-dict vocab-size:13 num-oods:5 (0.266809%) most-frequent:\"KB160\" 791 (42.2092%) dtype:DTYPE_BYTES\n",
      "\t1: \"c_wave-O\" CATEGORICAL has-dict vocab-size:5 num-oods:2 (0.106724%) most-frequent:\"CM127\" 1476 (78.762%) dtype:DTYPE_BYTES\n",
      "\t2: \"middle_sheet-O\" CATEGORICAL has-dict vocab-size:5 num-oods:7 (0.373533%) most-frequent:\"None\" 1066 (56.8837%) dtype:DTYPE_BYTES\n",
      "\t3: \"b_wave-O\" CATEGORICAL has-dict vocab-size:8 num-oods:5 (0.266809%) most-frequent:\"None\" 919 (49.0395%) dtype:DTYPE_BYTES\n",
      "\t4: \"back_sheet-O\" CATEGORICAL has-dict vocab-size:10 num-oods:4 (0.213447%) most-frequent:\"KB160\" 884 (47.1718%) dtype:DTYPE_BYTES\n",
      "\t5: \"back_sheet-P\" CATEGORICAL has-dict vocab-size:18 zero-ood-items most-frequent:\"KB160\" 624 (33.2978%) dtype:DTYPE_BYTES\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "No input feature explicitly specified. Using all the available input features.\n",
      "The label \"back_sheet-P\" was removed from the input feature set.\n",
      "Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
      "Training gradient boosted tree on 1874 example(s) and 5 feature(s).\n",
      "1709 examples used for training and 165 examples used for validation\n",
      "\tnum-trees:1 train-loss:2.181285 train-accuracy:0.573435 valid-loss:2.175209 valid-accuracy:0.575758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained in 0:00:01.052757\n",
      "back_sheet-Ptest accuracy: 0.5550239234449761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 1.18614\n",
      "Truncates the model to 612 tree(s) i.e. 36  iteration(s).\n",
      "Final model num-trees:36 valid-loss:1.186140 valid-accuracy:0.587879\n",
      "Model loaded with 612 root(s), 21174 node(s), and 5 input feature(s).\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "\n",
    "for paper in output:\n",
    "    model[paper] = ydf.GradientBoostedTreesLearner(label=f'{paper}', features=input).train(df_train)\n",
    "    # model[paper].save(f\"modules/yggdrasil_models/{paper}\")\n",
    "    evaluation = model[paper].evaluate(df_test)\n",
    "    # Query individual evaluation metrics\n",
    "    print(f\"{paper}test accuracy: {evaluation.accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [['KAC125' 'CM112' 'None' 'None' 'KB120']]\n",
      "\n",
      "Predictions:\n",
      "\n",
      "front_sheet-P:\n",
      "  1. Probability: 62.16%, Type: KA125\n",
      "  2. Probability: 37.21%, Type: KAC125\n",
      "  3. Probability: 0.24%, Type: KB120\n",
      "  4. Probability: 0.09%, Type: KI128\n",
      "  5. Probability: 0.05%, Type: KL125\n",
      "  6. Probability: 0.04%, Type: KAC155\n",
      "  7. Probability: 0.03%, Type: CM127\n",
      "  8. Probability: 0.03%, Type: KA155\n",
      "  9. Probability: 0.03%, Type: KA225\n",
      "  10. Probability: 0.02%, Type: WLK154\n",
      "  11. Probability: 0.02%, Type: KB160\n",
      "  12. Probability: 0.02%, Type: CM97\n",
      "  13. Probability: 0.01%, Type: WLK174\n",
      "  14. Probability: 0.01%, Type: KI158\n",
      "  15. Probability: 0.01%, Type: KS121\n",
      "  acc: 46.00%\n",
      "\n",
      "c_wave-P:\n",
      "  1. Probability: 94.30%, Type: CM112\n",
      "  2. Probability: 4.84%, Type: CM127\n",
      "  3. Probability: 0.44%, Type: CME100\n",
      "  4. Probability: 0.35%, Type: None\n",
      "  5. Probability: 0.06%, Type: CM197\n",
      "  acc: 66.06%\n",
      "\n",
      "middle_sheet-P:\n",
      "  1. Probability: 100.00%, Type: None\n",
      "  acc: 83.03%\n",
      "\n",
      "b_wave-P:\n",
      "  1. Probability: 99.71%, Type: None\n",
      "  2. Probability: 0.15%, Type: CM100\n",
      "  3. Probability: 0.06%, Type: CM112\n",
      "  4. Probability: 0.05%, Type: CM97\n",
      "  5. Probability: 0.03%, Type: CME100\n",
      "  acc: 85.86%\n",
      "\n",
      "back_sheet-P:\n",
      "  1. Probability: 56.10%, Type: KB120\n",
      "  2. Probability: 20.56%, Type: CM112\n",
      "  3. Probability: 13.29%, Type: CM127\n",
      "  4. Probability: 8.78%, Type: CME100\n",
      "  5. Probability: 0.42%, Type: CM197\n",
      "  6. Probability: 0.19%, Type: CM97\n",
      "  7. Probability: 0.16%, Type: KAC155\n",
      "  8. Probability: 0.15%, Type: CM100\n",
      "  9. Probability: 0.11%, Type: KA225\n",
      "  10. Probability: 0.09%, Type: KA155\n",
      "  11. Probability: 0.08%, Type: CM147\n",
      "  12. Probability: 0.03%, Type: KL250\n",
      "  13. Probability: 0.01%, Type: KA185\n",
      "  14. Probability: 0.01%, Type: KAC225\n",
      "  acc: 55.34%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class CNB:\n",
    "    df_data: pd.DataFrame\n",
    "    nb_input: pd.DataFrame\n",
    "    input = ['front_sheet-O', 'c_wave-O', 'middle_sheet-O', 'b_wave-O', 'back_sheet-O']\n",
    "    output = ['front_sheet-P', 'c_wave-P', 'middle_sheet-P', 'b_wave-P', 'back_sheet-P']\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.nb_output = {}\n",
    "        data = self.df_data[input]\n",
    "        input_enc = OrdinalEncoder()\n",
    "        input_enc.fit(data)\n",
    "        self.input_enc = input_enc\n",
    "        X = input_enc.set_params(encoded_missing_value=-1).transform(data)\n",
    "        nb_input = input_enc.set_params(encoded_missing_value=-1).transform(self.nb_input)\n",
    "        self.nb_input = nb_input\n",
    "        for paper_type in output:\n",
    "            label = self.df_data[[paper_type]]\n",
    "            output_enc = OrdinalEncoder()\n",
    "            output_enc.fit(label)\n",
    "            y = output_enc.set_params(encoded_missing_value=-1).transform(label)\n",
    "            \n",
    "            clf = CategoricalNB()\n",
    "            clf.fit(X, y.ravel())\n",
    "            \n",
    "            # Get predicted probabilities\n",
    "            pred_proba = clf.predict_proba(nb_input)\n",
    "            \n",
    "            # Get the predicted classes\n",
    "            pred = clf.predict(nb_input)\n",
    "            \n",
    "            # Prepare predictions for output\n",
    "            predictions = []\n",
    "            for i in range(len(pred_proba[0])):\n",
    "                class_label = output_enc.inverse_transform([[i]])[0]  # Reshape for inverse_transform\n",
    "                prob = pred_proba[0][i]\n",
    "                predictions.append((prob, class_label))\n",
    "            \n",
    "            # Sort predictions by probability in descending order\n",
    "            predictions.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "            pred_output = {}\n",
    "            for i, (prob, cls) in enumerate(predictions, start=1):\n",
    "                if prob <= 0.0001: break\n",
    "                cls_out = ''.join(cls)\n",
    "                pred_output[i]={'proba': f'{prob:.2%}', 'type':f'{cls_out}'}\n",
    "            pred_output['acc'] = f\"{clf.score(X,y):.2%}\"\n",
    "            self.nb_output[f'{paper_type}']=pred_output\n",
    "\n",
    "    def get(self):\n",
    "        return self.nb_output\n",
    "\n",
    "    def show(self):\n",
    "        # Decode input\n",
    "        input_decoded = self.input_enc.inverse_transform(self.nb_input) \n",
    "        print(f'Input: {input_decoded}\\n')\n",
    "        \n",
    "        print('Predictions:\\n')\n",
    "        \n",
    "        # Print the dictionary contents with improved formatting\n",
    "        for key, values in self.nb_output.items():\n",
    "            print(f\"{key}:\")\n",
    "            \n",
    "            for item, details in values.items():\n",
    "                if isinstance(details, dict):\n",
    "                    proba = details.get('proba', 'N/A')\n",
    "                    paper_type = details.get('type', 'N/A')\n",
    "                    print(f\"  {item}. Probability: {proba}, Type: {paper_type}\")\n",
    "                else:\n",
    "                    print(f\"  {item}: {details}\")\n",
    "            \n",
    "            print() \n",
    "        \n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    'front_sheet-O': 'KAC125',\n",
    "    'c_wave-O': 'CM112',\n",
    "    'middle_sheet-O': 'None',\n",
    "    'b_wave-O': 'None',\n",
    "    'back_sheet-O': 'KB120'\n",
    "}\n",
    "nb_input = pd.DataFrame(data_dict, index=[0]) \n",
    "\n",
    "cnb_instance = CNB(df_data=df_train,nb_input=nb_input)\n",
    "cnb_instance.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.naive_bayes import CategoricalNB\n",
    "# clf = CategoricalNB()\n",
    "# clf.fit(X, y.ravel())\n",
    "# nb_input = X[3:4]\n",
    "# pred = clf.predict(nb_input)\n",
    "# print('input',input_enc.inverse_transform(nb_input))\n",
    "# print('output\\n',output_enc.inverse_transform(pred.reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[col for col in col_names if f'{paper_part}-P' not in col]].copy()\n",
    "y = df[f'{paper_part}-P'].copy()\n",
    "# split data into training and testing sets\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "import category_encoders as ce\n",
    "# encode categorical variables with ordinal encoding\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=[f'{paper_part}-O'])\n",
    "\n",
    "\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the classifier with n_estimators = 100\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_100 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "rfc_100.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predict on the test set results\n",
    "\n",
    "y_pred_100 = rfc_100.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Check accuracy score \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    f'{paper_part}-O': ['CM127     '],\n",
    "}\n",
    "\n",
    "test = pd.DataFrame(test_data)\n",
    "print(test)\n",
    "\n",
    "X = encoder.transform(test)\n",
    "\n",
    "first_row = X.iloc[0]\n",
    "print(first_row)\n",
    "print(rfc_100.predict([first_row]))\n",
    "\n",
    "\n",
    "import joblib\n",
    "joblib.dump(rfc_100, f'{paper_part}P_randomforest.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the classifier with n_estimators = 100\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# fit the model to the training set\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the feature scores\n",
    "\n",
    "feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a seaborn bar plot\n",
    "\n",
    "sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "\n",
    "\n",
    "\n",
    "# Add labels to the graph\n",
    "\n",
    "plt.xlabel('Feature Importance Score')\n",
    "\n",
    "plt.ylabel('Features')\n",
    "\n",
    "\n",
    "\n",
    "# Add title to the graph\n",
    "\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "\n",
    "\n",
    "\n",
    "# Visualize the graph\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
